{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† House Price Prediction - Complete Project\n",
    "## End-to-End Machine Learning Project\n",
    "\n",
    "### Project Overview\n",
    "- **Objective**: Predict house prices based on property features\n",
    "- **Dataset**: Housing data with various features\n",
    "- **Approach**: Regression modeling with multiple algorithms\n",
    "- **Deployment**: Streamlit web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('house_data.csv')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*60)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*60)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
    "print(missing_df[missing_df['Missing'] > 0])\n",
    "print(f\"\\nTotal missing values: {missing.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable (Price)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Price'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Price ($)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Price Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['Price'], vert=True)\n",
    "axes[1].set_ylabel('Price ($)', fontsize=12)\n",
    "axes[1].set_title('Price Box Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Statistics\n",
    "price_stats = df['Price'].describe()\n",
    "axes[2].axis('off')\n",
    "stats_text = f\"\"\"\n",
    "Price Statistics:\n",
    "\n",
    "Mean:     ${price_stats['mean']:,.2f}\n",
    "Median:   ${price_stats['50%']:,.2f}\n",
    "Std Dev:  ${price_stats['std']:,.2f}\n",
    "Min:      ${price_stats['min']:,.2f}\n",
    "Max:      ${price_stats['max']:,.2f}\n",
    "\"\"\"\n",
    "axes[2].text(0.1, 0.5, stats_text, fontsize=12, family='monospace',\n",
    "            verticalalignment='center')\n",
    "axes[2].set_title('Price Statistics', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features distribution\n",
    "numerical_cols = ['Area', 'Bedrooms', 'Bathrooms', 'Floors', 'YearBuilt']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].hist(df[col], bins=20, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features distribution\n",
    "categorical_cols = ['Location', 'Condition', 'Garage']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    value_counts = df[col].value_counts()\n",
    "    axes[idx].bar(value_counts.index, value_counts.values, color='lightgreen', edgecolor='black')\n",
    "    axes[idx].set_xlabel(col, fontsize=12)\n",
    "    axes[idx].set_ylabel('Count', fontsize=12)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=13, fontweight='bold')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlGn', center=0,\n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
    "plt.title('Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "price_corr = df[numerical_features].corr()['Price'].sort_values(ascending=False)\n",
    "print(\"Correlation with Price:\")\n",
    "print(\"=\"*60)\n",
    "print(price_corr)\n",
    "\n",
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "price_corr.drop('Price').plot(kind='barh', color=['green' if x > 0 else 'red' for x in price_corr.drop('Price')])\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.title('Feature Correlation with Price', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Features vs Price\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].scatter(df[col], df['Price'], alpha=0.5, s=30)\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Price ($)', fontsize=11)\n",
    "    axes[idx].set_title(f'{col} vs Price', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df[col], df['Price'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(df[col], p(df[col]), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots: Categorical features vs Price\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    df.boxplot(column='Price', by=col, ax=axes[idx])\n",
    "    axes[idx].set_xlabel(col, fontsize=12)\n",
    "    axes[idx].set_ylabel('Price ($)', fontsize=12)\n",
    "    axes[idx].set_title(f'{col} vs Price', fontsize=13, fontweight='bold')\n",
    "    axes[idx].get_figure().suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Drop Id column if exists\n",
    "if 'Id' in df_clean.columns:\n",
    "    df_clean = df_clean.drop('Id', axis=1)\n",
    "    print(\"‚úÖ Dropped 'Id' column\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# Handle missing values (if any)\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        if df_clean[col].dtype in ['int64', 'float64']:\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "        else:\n",
    "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset cleaned: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "df_clean['Age'] = 2025 - df_clean['YearBuilt']\n",
    "df_clean['TotalRooms'] = df_clean['Bedrooms'] + df_clean['Bathrooms']\n",
    "df_clean['Area_per_Room'] = df_clean['Area'] / df_clean['TotalRooms']\n",
    "\n",
    "print(\"‚úÖ New features created:\")\n",
    "print(\"   - Age (house age in years)\")\n",
    "print(\"   - TotalRooms (bedrooms + bathrooms)\")\n",
    "print(\"   - Area_per_Room (area divided by total rooms)\")\n",
    "\n",
    "print(f\"\\nDataset shape after feature engineering: {df_clean.shape}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "label_encoders = {}\n",
    "\n",
    "print(\"Encoding categorical variables:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"\\n{col}:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        print(f\"  {class_name} ‚Üí {i}\")\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "print(\"\\n‚úÖ Label encoders saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_clean.drop('Price', axis=1)\n",
    "y = df_clean['Price']\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set:   {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set:       {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(\"‚úÖ Scaler saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Training Models:\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Train MSE': train_mse, 'Test MSE': test_mse,\n",
    "        'Train RMSE': train_rmse, 'Test RMSE': test_rmse,\n",
    "        'Train MAE': train_mae, 'Test MAE': test_mae,\n",
    "        'Train R¬≤': train_r2, 'Test R¬≤': test_r2\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nüìä Training Metrics:\")\n",
    "    print(f\"   MSE:  ${train_mse:,.2f}\")\n",
    "    print(f\"   RMSE: ${train_rmse:,.2f}\")\n",
    "    print(f\"   MAE:  ${train_mae:,.2f}\")\n",
    "    print(f\"   R¬≤:   {train_r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Test Metrics:\")\n",
    "    print(f\"   MSE:  ${test_mse:,.2f}\")\n",
    "    print(f\"   RMSE: ${test_rmse:,.2f}\")\n",
    "    print(f\"   MAE:  ${test_mae:,.2f}\")\n",
    "    print(f\"   R¬≤:   {test_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ All models trained successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(results_df)\n",
    "\n",
    "# Best model\n",
    "best_model_name = results_df['Test R¬≤'].idxmax()\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Test R¬≤: {results_df.loc[best_model_name, 'Test R¬≤']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# R¬≤ Score\n",
    "axes[0, 0].bar(results_df.index, results_df['Test R¬≤'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0, 0].set_title('R¬≤ Score Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('R¬≤ Score')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].bar(results_df.index, results_df['Test RMSE'],\n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0, 1].set_title('RMSE Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('RMSE ($)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# MAE\n",
    "axes[1, 0].bar(results_df.index, results_df['Test MAE'],\n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[1, 0].set_title('MAE Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('MAE ($)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Train vs Test R¬≤\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[1, 1].bar(x - width/2, results_df['Train R¬≤'], width, \n",
    "              label='Train', color='#95E1D3')\n",
    "axes[1, 1].bar(x + width/2, results_df['Test R¬≤'], width,\n",
    "              label='Test', color='#F38181')\n",
    "axes[1, 1].set_title('Train vs Test R¬≤', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('R¬≤ Score')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(results_df.index)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and save best model\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model, 'house_price_model.pkl')\n",
    "\n",
    "# Save feature names\n",
    "feature_names = list(X.columns)\n",
    "joblib.dump(feature_names, 'feature_names.pkl')\n",
    "\n",
    "print(\"\\n‚úÖ Model and artifacts saved:\")\n",
    "print(\"   - house_price_model.pkl\")\n",
    "print(\"   - scaler.pkl\")\n",
    "print(\"   - label_encoders.pkl\")\n",
    "print(\"   - feature_names.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Prediction analysis\n",
    "pred_analysis = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred,\n",
    "    'Error': y_test.values - y_pred,\n",
    "    'Abs Error': np.abs(y_test.values - y_pred),\n",
    "    'Pct Error': np.abs((y_test.values - y_pred) / y_test.values) * 100\n",
    "})\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*60)\n",
    "print(pred_analysis.head(10))\n",
    "print(f\"\\nAverage Absolute Error: ${pred_analysis['Abs Error'].mean():,.2f}\")\n",
    "print(f\"Average Percentage Error: {pred_analysis['Pct Error'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.6, s=50)\n",
    "axes[0].plot([y_test.min(), y_test.max()], \n",
    "             [y_test.min(), y_test.max()], \n",
    "             'r--', lw=3, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Price ($)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Price ($)', fontsize=12)\n",
    "axes[0].set_title('Actual vs Predicted Prices', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.6, s=50)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=3)\n",
    "axes[1].set_xlabel('Predicted Price ($)', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals ($)', fontsize=12)\n",
    "axes[1].set_title('Residual Plot', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "axes[2].hist(pred_analysis['Pct Error'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[2].axvline(pred_analysis['Pct Error'].mean(), \n",
    "               color='red', linestyle='--', lw=2, \n",
    "               label=f'Mean: {pred_analysis[\"Pct Error\"].mean():.2f}%')\n",
    "axes[2].set_xlabel('Percentage Error (%)', fontsize=12)\n",
    "axes[2].set_ylabel('Frequency', fontsize=12)\n",
    "axes[2].set_title('Distribution of Percentage Errors', fontsize=13, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ PROJECT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Training samples: {len(X_train)}\")\n",
    "print(f\"   Test samples: {len(X_test)}\")\n",
    "print(f\"   Number of features: {X.shape[1]}\")\n",
    "print(f\"\\nüîß Features Used:\")\n",
    "for i, feature in enumerate(X.columns, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"\\nüìà Performance Metrics (Test Set):\")\n",
    "print(f\"   R¬≤ Score:  {results_df.loc[best_model_name, 'Test R¬≤']:.4f}\")\n",
    "print(f\"   RMSE:      ${results_df.loc[best_model_name, 'Test RMSE']:,.2f}\")\n",
    "print(f\"   MAE:       ${results_df.loc[best_model_name, 'Test MAE']:,.2f}\")\n",
    "print(f\"   Avg Error: {pred_analysis['Pct Error'].mean():.2f}%\")\n",
    "print(f\"\\nüíæ Files Saved:\")\n",
    "print(f\"   ‚úì house_price_model.pkl - Trained model\")\n",
    "print(f\"   ‚úì scaler.pkl - Feature scaler\")\n",
    "print(f\"   ‚úì label_encoders.pkl - Categorical encoders\")\n",
    "print(f\"   ‚úì feature_names.pkl - Feature names\")\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Deploy the model using Streamlit: streamlit run app.py\")\n",
    "print(f\"   2. Test the model with new data\")\n",
    "print(f\"   3. Monitor model performance over time\")\n",
    "print(f\"   4. Consider hyperparameter tuning for improvement\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Project completed successfully!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
